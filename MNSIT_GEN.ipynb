{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Sequential\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the mnsit dataset\n",
    "dataset = datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 15 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#display some examples from the dataset\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#display the first 15 images in the dataset\n",
    "for i in range(15):\n",
    "    plt.subplot(3, 5, i+1)\n",
    "    plt.imshow(dataset.data[i].numpy(), cmap='gray')\n",
    "    plt.title('%i' % dataset.targets[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " #test split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(dataset.data, dataset.targets, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize train_data and test_data\n",
    "train_data = train_data/255.0\n",
    "test_data = test_data/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_losses_train = []\n",
    "discriminator_losses_train = []\n",
    "generator_losses_test = []\n",
    "discriminator_losses_test = []\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#The main class for GANs \n",
    "class generator():\n",
    "    def __init__(self, input_shape,hidden_shapes,output_shape):\n",
    "\n",
    "        self.input_shape = input_shape\n",
    "        self.model = Sequential(\n",
    "            nn.Linear(input_shape,hidden_shapes[0]),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_shapes[0],hidden_shapes[1]),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_shapes[1],output_shape),\n",
    "            nn.Sigmoid()\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self,img):\n",
    "        x = self.model(img)\n",
    "        return x\n",
    "\n",
    "class discriminator():\n",
    "    def __init__(self, input_shape,hidden_shapes):\n",
    "        self.input_shape = input_shape\n",
    "        self.model = Sequential(\n",
    "            nn.Linear(input_shape,hidden_shapes[0]),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_shapes[0],hidden_shapes[1]),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_shapes[1],1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self,img):\n",
    "        x = self.model(img)\n",
    "        return x\n",
    "\n",
    "class GAN():\n",
    "    def __init__(self,img_width,img_height,hidden_shapes_generator,hidden_shapes_discriminator,input_shape = 100, output_shape = None,batch_size= 64):\n",
    "        if output_shape == None:\n",
    "            output_shape = img_width*img_height\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "        self.generator = generator(input_shape,hidden_shapes_generator,output_shape)\n",
    "        self.discriminator = discriminator(output_shape,hidden_shapes_discriminator)\n",
    "        self.loss = nn.BCELoss()\n",
    "        self.generator_optimizer = torch.optim.Adam(self.generator.model.parameters(),lr=0.002)\n",
    "        self.discriminator_optimizer = torch.optim.Adam(self.discriminator.model.parameters(),lr=0.002)\n",
    "        self.batch_size = batch_size   \n",
    "        self.real_labels =  torch.ones(self.batch_size).reshape(-1, 1)\n",
    "        self.fake_labels = torch.zeros(self.batch_size).reshape(-1, 1)\n",
    "\n",
    "\n",
    "    def train(self,train_data,epochs=10):\n",
    "        for epoch in range(epochs):\n",
    "            noises = torch.rand(len(train_data),self.input_shape).float()\n",
    "            for i in range(0,len(train_data),self.batch_size):\n",
    "\n",
    "                # Create noisy input for generator between 0 and 1\n",
    "\n",
    "                        # zero the gradients on each iteration\n",
    "                self.generator_optimizer.zero_grad()\n",
    "\n",
    "                # Create noisy input for generator\n",
    "                # Need float type instead of int\n",
    "\n",
    "                generated_data = self.generator.model(noises[i:i+self.batch_size])\n",
    "\n",
    "                # Generate examples of even real data\n",
    "                true_data = train_data[i:i+self.batch_size].view(-1,28*28).float()\n",
    "\n",
    "\n",
    "                # Train the generator\n",
    "                # We invert the labels here and don't train the discriminator because we want the generator\n",
    "                # to make things the discriminator classifies as true.\n",
    "                generator_discriminator_out = self.discriminator.model(generated_data)\n",
    "                generator_loss = self.loss(generator_discriminator_out, self.real_labels)\n",
    "                generator_loss.backward()\n",
    "                self.generator_optimizer.step()\n",
    "\n",
    "                # Train the discriminator on the true/generated data\n",
    "                self.discriminator_optimizer.zero_grad()\n",
    "                true_discriminator_out = self.discriminator.model(true_data)\n",
    "                true_discriminator_loss = self.loss(true_discriminator_out, self.real_labels)\n",
    "\n",
    "                # add .detach() here think about this\n",
    "                # Train the discriminator\n",
    "                self.discriminator_optimizer.zero_grad()\n",
    "                true_discriminator_out = self.discriminator.model(true_data)\n",
    "                true_discriminator_loss = self.loss(true_discriminator_out, self.real_labels)\n",
    "                generator_discriminator_out = self.discriminator.model(generated_data.detach())\n",
    "                generator_discriminator_loss = self.loss(generator_discriminator_out,self.fake_labels)\n",
    "                discriminator_loss = (true_discriminator_loss + generator_discriminator_loss) / 2\n",
    "    \n",
    "                discriminator_loss.backward()\n",
    "                self.discriminator_optimizer.step()\n",
    "                generator_losses_train.append(generator_loss.item())\n",
    "                discriminator_losses_train.append(discriminator_loss.item()) \n",
    "            #show some generated examples in a grid \n",
    "            if epoch%5 == 0:\n",
    "                #test the generator on the test set and calculate the loss\n",
    "                noises = torch.rand(len(test_data),self.input_shape).float()\n",
    "                generated_data = self.generator.model(noises)\n",
    "                true_data = test_data.view(-1,28*28).float()\n",
    "                #shuffle the test data\n",
    "                true_data = true_data[torch.randperm(true_data.size()[0])]\n",
    "                generator_discriminator_out = self.discriminator.model(generated_data)\n",
    "                discriminator_discriminator_out = self.discriminator.model(true_data)\n",
    "                for i in range(0,len(test_data),self.batch_size):\n",
    "                    generator_loss = self.loss(generator_discriminator_out[i:i+self.batch_size], self.real_labels[:min(self.batch_size,len(test_data)-i)])\n",
    "                    generator_losses_test.append(generator_loss.item())\n",
    "                    discriminator_loss = self.loss(discriminator_discriminator_out[i:i+self.batch_size], self.real_labels[:min(self.batch_size,len(test_data)-i)])\n",
    "                    discriminator_losses_test.append(discriminator_loss.item())\n",
    "\n",
    "                print(\"Epoch: \", epoch)\n",
    "                print(\"Generator loss: \", generator_loss.item())\n",
    "                print(\"Discriminator loss: \", discriminator_loss.item())\n",
    "                noises = torch.randn(8, self.input_shape).float()\n",
    "                generated_data = self.generator.model(noises)\n",
    "\n",
    "                fig, axs = plt.subplots(1,8, figsize=(20, 2), dpi=80)\n",
    "                fig.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "                for i, ax in enumerate(axs.ravel()):\n",
    "                    ax.imshow(generated_data[i].detach().numpy().reshape(28, 28), cmap='gray')\n",
    "                    ax.axis('off')\n",
    "\n",
    "                plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Using a target size (torch.Size([64, 1])) that is different to the input size (torch.Size([32, 1])) is deprecated. Please ensure they have the same size.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m gan \u001b[39m=\u001b[39m GAN(\u001b[39m28\u001b[39m,\u001b[39m28\u001b[39m,[\u001b[39m256\u001b[39m,\u001b[39m128\u001b[39m],[\u001b[39m256\u001b[39m,\u001b[39m128\u001b[39m])\n\u001b[0;32m      4\u001b[0m \u001b[39m#train the GAN\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m gan\u001b[39m.\u001b[39;49mtrain(train_data,epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[11], line 112\u001b[0m, in \u001b[0;36mGAN.train\u001b[1;34m(self, train_data, epochs)\u001b[0m\n\u001b[0;32m    110\u001b[0m     generator_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss(generator_discriminator_out[i:i\u001b[39m+\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreal_labels[:\u001b[39mmin\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size,\u001b[39mlen\u001b[39m(test_data)\u001b[39m-\u001b[39mi)])\n\u001b[0;32m    111\u001b[0m     generator_losses_test\u001b[39m.\u001b[39mappend(generator_loss\u001b[39m.\u001b[39mitem())\n\u001b[1;32m--> 112\u001b[0m     discriminator_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss(discriminator_discriminator_out[i:i\u001b[39m+\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_size], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreal_labels)\n\u001b[0;32m    113\u001b[0m     discriminator_losses_test\u001b[39m.\u001b[39mappend(discriminator_loss\u001b[39m.\u001b[39mitem())\n\u001b[0;32m    115\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m\"\u001b[39m, epoch)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\loss.py:619\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 619\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbinary_cross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\functional.py:3089\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[1;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3087\u001b[0m     reduction_enum \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mget_enum(reduction)\n\u001b[0;32m   3088\u001b[0m \u001b[39mif\u001b[39;00m target\u001b[39m.\u001b[39msize() \u001b[39m!=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize():\n\u001b[1;32m-> 3089\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   3090\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUsing a target size (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) that is different to the input size (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) is deprecated. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3091\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease ensure they have the same size.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(target\u001b[39m.\u001b[39msize(), \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[0;32m   3092\u001b[0m     )\n\u001b[0;32m   3094\u001b[0m \u001b[39mif\u001b[39;00m weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3095\u001b[0m     new_size \u001b[39m=\u001b[39m _infer_size(target\u001b[39m.\u001b[39msize(), weight\u001b[39m.\u001b[39msize())\n",
      "\u001b[1;31mValueError\u001b[0m: Using a target size (torch.Size([64, 1])) that is different to the input size (torch.Size([32, 1])) is deprecated. Please ensure they have the same size."
     ]
    }
   ],
   "source": [
    "#initialize the GAN\n",
    "gan = GAN(28,28,[256,128],[256,128])\n",
    "\n",
    "#train the GAN\n",
    "gan.train(train_data,epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "#import Tuple List\n",
    "from typing import Tuple, List\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_binary_list_from_int(number: int) -> List[int]:\n",
    "    if number < 0 or type(number) is not int:\n",
    "        raise ValueError(\"Only Positive integers are allowed\")\n",
    "\n",
    "    return [int(x) for x in list(bin(number))[2:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_even_data(max_int: int, batch_size: int=16) -> Tuple[List[int], List[List[int]]]:\n",
    "    # Get the number of binary places needed to represent the maximum number\n",
    "    max_length = int(math.log(max_int, 2))\n",
    "\n",
    "    # Sample batch_size number of integers in range 0-max_int\n",
    "    sampled_integers = np.random.randint(0, int(max_int / 2), batch_size)\n",
    "\n",
    "    # create a list of labels all ones because all numbers are even\n",
    "    labels = [1] * batch_size\n",
    "\n",
    "    # Generate a list of binary numbers for training.\n",
    "    data = [create_binary_list_from_int(int(x * 2)) for x in sampled_integers]\n",
    "    data = [([0] * (max_length - len(x))) + x for x in data]\n",
    "\n",
    "    return labels, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_length: int):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.dense = nn.Linear(int(input_length), 1);\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.activation(self.dense(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, input_length: int):\n",
    "        super(Generator, self).__init__()\n",
    "        self.dense_layer = nn.Linear(int(input_length), int(input_length))\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.activation(self.dense_layer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def train(max_int: int = 128, batch_size: int = 16, training_steps: int = 500):\n",
    "    input_length = int(math.log(max_int, 2))\n",
    "\n",
    "    # Models\n",
    "    generator = Generator(input_length)\n",
    "    discriminator = Discriminator(input_length)\n",
    "\n",
    "    # Optimizers\n",
    "    generator_optimizer = torch.optim.Adam(generator.parameters(), lr=0.001)\n",
    "    discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.001)\n",
    "\n",
    "    # loss\n",
    "    loss = nn.BCELoss()\n",
    "\n",
    "    for i in range(training_steps):\n",
    "        # zero the gradients on each iteration\n",
    "        generator_optimizer.zero_grad()\n",
    "\n",
    "        # Create noisy input for generator\n",
    "        # Need float type instead of int\n",
    "        noise = torch.randint(0, 2, size=(batch_size, input_length)).float()\n",
    "        generated_data = generator(noise)\n",
    "\n",
    "        # Generate examples of even real data\n",
    "        true_labels, true_data = generate_even_data(max_int, batch_size=batch_size)\n",
    "        true_labels = torch.tensor(true_labels).float()\n",
    "        true_data = torch.tensor(true_data).float()\n",
    "\n",
    "        # Train the generator\n",
    "        # We invert the labels here and don't train the discriminator because we want the generator\n",
    "        # to make things the discriminator classifies as true.\n",
    "        generator_discriminator_out = discriminator(generated_data)\n",
    "        generator_loss = loss(generator_discriminator_out, true_labels.reshape(-1, 1))\n",
    "        generator_loss.backward()\n",
    "        generator_optimizer.step()\n",
    "\n",
    "        # Train the discriminator on the true/generated data\n",
    "        discriminator_optimizer.zero_grad()\n",
    "        true_discriminator_out = discriminator(true_data)\n",
    "        true_discriminator_loss = loss(true_discriminator_out, true_labels.reshape(-1, 1))\n",
    "\n",
    "        # add .detach() here think about this\n",
    "        # Train the discriminator\n",
    "        discriminator_optimizer.zero_grad()\n",
    "        true_discriminator_out = discriminator(true_data)\n",
    "        true_discriminator_loss = loss(true_discriminator_out, torch.ones(batch_size).reshape(-1, 1))\n",
    "        generator_discriminator_out = discriminator(generated_data.detach())\n",
    "        generator_discriminator_loss = loss(generator_discriminator_out, torch.zeros(batch_size).reshape(-1, 1))\n",
    "        discriminator_loss = (true_discriminator_loss + generator_discriminator_loss) / 2\n",
    "        print (generator_discriminator_loss, true_discriminator_loss)\n",
    "        discriminator_loss.backward()\n",
    "        discriminator_optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0812, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.4953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.0749, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5362, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.0673, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5159, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.0817, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.0788, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5287, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.0748, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5000, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.0634, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5282, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.0606, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5336, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.0668, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5398, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.0657, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.4985, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.0658, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.4991, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.0612, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5403, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.0571, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5114, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.0613, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.4946, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.0450, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5335, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.0518, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5423, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.0450, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5087, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.0502, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.0443, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5645, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.0492, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5084, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.0459, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5238, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.0436, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5062, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.0340, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5425, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.0349, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5398, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.0278, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5484, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.0244, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5236, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.0268, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5090, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.0252, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5213, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.0258, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.0355, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5162, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.0334, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5198, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.0260, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5528, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.0140, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5371, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.0108, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5256, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.0261, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5523, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.0159, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5342, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.0192, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5717, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.0207, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5134, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.0098, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5624, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.0017, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5450, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.0129, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5866, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.0026, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5750, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9999, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9987, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5428, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.0129, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5550, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9964, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5831, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.0023, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5621, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.0053, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5574, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9999, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5391, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9900, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5604, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9870, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5907, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9842, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9839, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9932, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5869, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9777, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9733, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5481, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9748, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5690, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9783, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5674, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9706, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5600, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9664, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5971, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9713, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5780, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9615, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5369, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9706, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5885, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9726, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5846, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9584, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6120, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9674, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9531, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9547, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5787, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9676, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6139, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9605, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6086, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9580, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6027, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9613, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6240, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9493, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5777, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9466, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9384, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9472, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6461, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9363, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9464, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6176, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9516, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5802, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9351, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6036, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9420, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6114, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9353, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6348, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9348, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6265, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9355, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5761, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9284, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6021, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9182, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6209, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9378, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6176, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9289, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5871, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9237, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6332, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9235, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6183, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9166, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9292, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9211, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6310, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9176, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6087, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9145, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6544, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9113, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6155, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9175, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6189, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9072, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5974, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8992, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6033, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9083, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6080, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9002, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5989, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9098, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6133, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8931, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9018, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6175, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8906, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6501, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8945, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.5768, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8980, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6157, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8942, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6465, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8867, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6253, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8925, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6284, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8923, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6140, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8817, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6478, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8948, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6197, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8862, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6628, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8833, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6463, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8833, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6352, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8910, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6766, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8687, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6100, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8734, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6471, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8698, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6622, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8729, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6540, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8742, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6349, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8669, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6404, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8752, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6636, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8718, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6408, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8655, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6509, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8649, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6539, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8670, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6486, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8586, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6449, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8654, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6265, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8604, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6067, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8529, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8621, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6728, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8533, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6109, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8595, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6503, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8526, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8467, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6239, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8542, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6775, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8440, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6415, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8476, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8402, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6615, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8508, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6637, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8437, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6579, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8390, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6411, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8347, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6421, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8416, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6544, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8220, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6584, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8270, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6655, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8276, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6503, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8358, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8331, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6801, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8300, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8241, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8285, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6738, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8201, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6693, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8086, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6361, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8142, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7011, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8233, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6723, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8204, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8104, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8191, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6482, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8161, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8083, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8147, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6833, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8016, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6758, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8121, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6825, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7959, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6577, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8052, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6717, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7957, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6919, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7947, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7952, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7934, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6676, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7985, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6776, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7960, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6830, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7993, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6902, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7954, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6843, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7908, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6893, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7894, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6988, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7886, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7901, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6628, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7845, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7047, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7842, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6915, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7857, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6889, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7772, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7143, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7786, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6693, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7796, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7771, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6894, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7831, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6644, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7737, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7118, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7804, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6968, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7703, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6914, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7717, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7118, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7706, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7090, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7747, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7059, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7709, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7663, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7638, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7063, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7598, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6922, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7679, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6723, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7595, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7074, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7619, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6978, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7595, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7214, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7624, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7646, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7170, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7561, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6804, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7575, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7596, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6954, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7573, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6882, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7529, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7135, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7500, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7003, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7527, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7041, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7497, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7063, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7509, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7468, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6550, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7481, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6802, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7440, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7158, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7464, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7055, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7458, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6909, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7421, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6992, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7419, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7163, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7448, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7155, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7369, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7092, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7412, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7176, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7343, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7348, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7353, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7362, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7117, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7290, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6927, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7277, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7246, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7295, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7362, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7330, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6992, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7302, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7089, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7282, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7298, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7295, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7227, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7281, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7123, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7262, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7191, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7300, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6923, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7254, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7255, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7218, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7219, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7218, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7031, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7180, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7129, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7194, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7102, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7202, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7078, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7210, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7208, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7168, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7075, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7177, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7116, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7155, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7162, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7166, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7097, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7121, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7162, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7122, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7248, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7098, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7194, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7090, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7186, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7049, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7179, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7103, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7261, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7084, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7315, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7074, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7248, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7064, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7178, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7016, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7312, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7002, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7236, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7025, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7214, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7042, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7149, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6991, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7452, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7007, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7445, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7005, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7127, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6997, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7301, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6963, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7288, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6940, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7202, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6982, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7251, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6969, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7393, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6955, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7290, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6962, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7102, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6969, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7321, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6937, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7302, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6907, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7453, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6952, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7321, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6904, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7155, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6917, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7248, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6909, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7325, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6901, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7327, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6883, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7361, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6877, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7242, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6916, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7151, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6863, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7364, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6885, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7129, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6874, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7213, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6896, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7394, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6868, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7351, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6865, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7373, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6860, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7210, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6868, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7249, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6822, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7269, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6856, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7218, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6805, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7231, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6834, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7256, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6827, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7361, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6817, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7290, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6830, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7283, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6808, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7199, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6815, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7245, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6804, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7283, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6807, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7281, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6802, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7158, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6792, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7219, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6790, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7102, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6796, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7255, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6780, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7217, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6781, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7116, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6770, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7134, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6775, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7301, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6756, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7281, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6771, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7182, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6751, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7186, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6752, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7177, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6753, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7137, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6746, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7210, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6741, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7172, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6735, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7178, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6737, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7348, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6736, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7121, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6731, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7164, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6744, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7142, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6746, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7265, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6735, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7162, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6732, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7251, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6726, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7211, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6720, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7052, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6721, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7195, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6709, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7217, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6698, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7045, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6702, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7136, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6708, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7210, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6693, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7164, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6697, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7048, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6692, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7136, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6680, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7171, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6677, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7103, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6671, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7176, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6682, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7221, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6682, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7157, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6676, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7144, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6671, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7092, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6672, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7150, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6681, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7114, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6667, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7019, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6669, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7029, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6670, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7178, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6664, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7151, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6665, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6665, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6667, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7086, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6668, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7004, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6662, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7100, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6656, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6647, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7092, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6652, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7109, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6665, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7069, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6656, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6928, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6662, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7094, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6644, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6667, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6878, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6636, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7102, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6636, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7068, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6645, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7132, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6641, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7007, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6635, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7041, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6650, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7039, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6622, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6952, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6623, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6942, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6635, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7031, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6638, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7017, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6626, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6972, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6609, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6603, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7042, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6608, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7128, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6611, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7024, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6598, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6920, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6607, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.7010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6602, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6965, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6595, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6990, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6610, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6852, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6585, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6588, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6908, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6603, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6906, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6612, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6903, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6615, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6583, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6917, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6578, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6571, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6850, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6598, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6964, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6603, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6915, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6557, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6778, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6566, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6566, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6959, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6594, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6993, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6570, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6748, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6569, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6774, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6569, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6791, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6576, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6904, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6561, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6809, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6562, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6570, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6557, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6750, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6586, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6866, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6576, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6896, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6575, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6744, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6547, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6712, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6604, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6740, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6526, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6556, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6725, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6534, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6958, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6550, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6889, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6541, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6689, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6567, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6803, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6540, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6589, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6535, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6718, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6532, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6519, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6893, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6556, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6723, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6532, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6806, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6534, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6768, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6532, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6895, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6510, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6967, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6533, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6883, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6601, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6809, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6534, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6769, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6559, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6771, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6526, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6849, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6528, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6802, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6506, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6869, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6523, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6632, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6519, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6635, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6566, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6758, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6544, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6799, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6481, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6767, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6590, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6819, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6560, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6808, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6547, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6539, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6560, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6571, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6516, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6642, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6543, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6409, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6536, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6650, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6541, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6688, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6524, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6602, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6567, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6655, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6551, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6532, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6765, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6514, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6719, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6522, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6634, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6507, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6698, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6550, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6585, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6495, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6704, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6555, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6604, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6493, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6758, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6509, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6538, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6642, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6519, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6554, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6501, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6495, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6529, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6548, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6478, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6544, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6542, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6628, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6511, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6468, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6507, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6689, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6520, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6680, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6514, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6466, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6501, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6530, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6526, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6810, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6446, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6543, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6515, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6557, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6493, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6721, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6470, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6532, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6465, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6373, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6553, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6433, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6466, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6426, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6540, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6454, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6510, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6580, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6513, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6350, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6552, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6608, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6503, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6664, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6561, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6497, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6521, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6401, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6578, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6554, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6529, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6395, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6549, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6741, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6531, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6718, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6532, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6550, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6642, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6454, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6413, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6559, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6768, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6523, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6838, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6527, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6443, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6515, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6430, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6295, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6513, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6842, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6611, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6544, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6494, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6439, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6518, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6643, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6507, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6518, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6474, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6347, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6505, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6397, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6525, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6551, grad_fn=<BinaryCrossEntropyBackward0>) tensor(0.6646, grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#train the GAN\n",
    "train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
